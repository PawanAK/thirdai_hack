{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-Vz_bEDphK1eSzss9v_kCqEtZN-7L9vp",
      "authorship_tag": "ABX9TyMIpPF4Dx1KFZEDJLwvJeO5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PawanAK/thirdai_hack/blob/main/chat_ube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcb_4-PY_xIM",
        "outputId": "183d8238-1157-4daf-ee72-aa61dfbfa40b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def convert_single_video(video_id):\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        return transcript\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "video_id = \"your_youtube_video_id_here\"\n",
        "transcript_data = convert_single_video(video_id)\n",
        "\n",
        "if transcript_data:\n",
        "    for entry in transcript_data:\n",
        "        start_time = entry['start']\n",
        "        text = entry['text']\n",
        "        print(f\"Start Time: {start_time}, Text: {text}\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the transcript.\")\n"
      ],
      "metadata": {
        "id": "_LQC7rftBcek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c4acef-0ef2-49e2-da73-a7adf7940dae"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: \n",
            "Could not retrieve a transcript for the video https://www.youtube.com/watch?v=your_youtube_video_id_here! This is most likely caused by:\n",
            "\n",
            "Subtitles are disabled for this video\n",
            "\n",
            "If you are sure that the described cause is not responsible for this error and that a transcript should be retrievable, please create an issue at https://github.com/jdepoix/youtube-transcript-api/issues. Please add which version of youtube_transcript_api you are using and provide the information needed to replicate the error. Also make sure that there are no open issues which already describe your problem!\n",
            "Failed to retrieve the transcript.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "video_id = input(\"Enter the YouTube video ID: \")\n",
        "transcript = convert_single_video(video_id)\n",
        "if transcript is not None:\n",
        "    csv_file_name = f\"{video_id}_transcript.csv\"\n",
        "    with open(csv_file_name, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
        "        csv_writer = csv.writer(csv_file)\n",
        "        csv_writer.writerow([\"Transcript\"])\n",
        "        for line in transcript:\n",
        "            csv_writer.writerow([line['text']])\n",
        "    print(f\"CSV transcript saved to {csv_file_name}\")\n",
        "else:\n",
        "    print(\"Transcript extraction failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9rlCiOnDVsE",
        "outputId": "5273e209-908d-465c-dd9a-cf4338736011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the YouTube video ID: DHjqpvDnNGE\n",
            "CSV transcript saved to DHjqpvDnNGE_transcript.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "csv_file_name = f\"{video_id}_transcript.csv\"\n",
        "df = pd.read_csv(csv_file_name)\n",
        "df['DOC_ID'] = range(len(df))\n",
        "df.to_csv(csv_file_name, index=False)\n",
        "print(\"DOC_ID added to CSV file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHlDJC5YDXp6",
        "outputId": "fe6a518f-050d-47bd-e291-4b87313fc619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOC_ID added to CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install thirdai --upgrade\n",
        "!pip3 install thirdai[neural_db]\n",
        "!pip3 install langchain --upgrade\n",
        "!pip3 install openai --upgrade\n",
        "!pip3 install paper-qa --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yIxWth1F2C5",
        "outputId": "e67d0332-25a3-44a1-d8a3-785eb0517c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thirdai\n",
            "  Downloading thirdai-0.7.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from thirdai) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from thirdai) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from thirdai) (2.27.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from thirdai) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->thirdai) (1.16.0)\n",
            "Installing collected packages: thirdai\n",
            "Successfully installed thirdai-0.7.16\n",
            "Requirement already satisfied: thirdai[neural_db] in /usr/local/lib/python3.10/dist-packages (0.7.16)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (2.27.1)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.5.3)\n",
            "Collecting PyTrie (from thirdai[neural_db])\n",
            "  Downloading PyTrie-0.4.0.tar.gz (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyMuPDF (from thirdai[neural_db])\n",
            "  Downloading PyMuPDF-1.22.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain (from thirdai[neural_db])\n",
            "  Downloading langchain-0.0.252-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4 (from thirdai[neural_db])\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting trafilatura (from thirdai[neural_db])\n",
            "  Downloading trafilatura-1.6.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx (from thirdai[neural_db])\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting url-normalize (from thirdai[neural_db])\n",
            "  Downloading url_normalize-1.4.3-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (3.8.1)\n",
            "Collecting unidecode (from thirdai[neural_db])\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from thirdai[neural_db]) (1.10.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai[neural_db]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->thirdai[neural_db]) (2022.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->thirdai[neural_db]) (4.11.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain->thirdai[neural_db])\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain->thirdai[neural_db])\n",
            "  Downloading langsmith-0.0.19-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain->thirdai[neural_db])\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->thirdai[neural_db]) (8.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->thirdai[neural_db]) (3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->thirdai[neural_db]) (4.65.0)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx->thirdai[neural_db]) (4.9.3)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from PyTrie->thirdai[neural_db]) (2.4.0)\n",
            "Collecting courlan>=0.9.3 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading courlan-0.9.3-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting htmldate>=1.4.3 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading htmldate-1.4.3-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting justext>=3.0.0 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading jusText-3.0.0-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of trafilatura to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting trafilatura (from thirdai[neural_db])\n",
            "  Downloading trafilatura-1.6.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.5.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.4.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading trafilatura-1.2.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from url-normalize->thirdai[neural_db]) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.3.1)\n",
            "Requirement already satisfied: langcodes>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.9.3->trafilatura->thirdai[neural_db]) (3.3.0)\n",
            "Collecting tld>=0.13 (from courlan>=0.9.3->trafilatura->thirdai[neural_db])\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db])\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db])\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting dateparser>=1.1.2 (from htmldate>=1.4.3->trafilatura->thirdai[neural_db])\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of htmldate to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting htmldate>=1.2.1 (from trafilatura->thirdai[neural_db])\n",
            "  Downloading htmldate-1.4.2-py3-none-any.whl (33 kB)\n",
            "  Downloading htmldate-1.4.1-py3-none-any.whl (33 kB)\n",
            "  Downloading htmldate-1.4.0-py3-none-any.whl (33 kB)\n",
            "  Downloading htmldate-1.3.2-py3-none-any.whl (39 kB)\n",
            "  Downloading htmldate-1.3.1-py3-none-any.whl (39 kB)\n",
            "  Downloading htmldate-1.3.0-py3-none-any.whl (32 kB)\n",
            "  Downloading htmldate-1.2.3-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->thirdai[neural_db]) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->thirdai[neural_db]) (2.4.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.4.3->trafilatura->thirdai[neural_db]) (5.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db])\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: bs4, python-docx, PyTrie\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=3f33d4aecea8cab81aef751b64b02324f907853b5b66dad253e3678058e4f1c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184489 sha256=652e677da5b29d03c2805bab56baa4926492a750845e3aaff20bcea54f9ba8fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "  Building wheel for PyTrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyTrie: filename=PyTrie-0.4.0-py3-none-any.whl size=6080 sha256=3b8a4d494cb2adfcc0dc47c57569631c0ded2632f688b024be44af5ccfc76023\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/0e/a3/3563272cb57af4afbc50c4c7882dd4540944aadde25c82bd45\n",
            "Successfully built bs4 python-docx PyTrie\n",
            "Installing collected packages: url-normalize, unidecode, tld, PyTrie, python-docx, PyMuPDF, mypy-extensions, marshmallow, justext, typing-inspect, openapi-schema-pydantic, langsmith, dateparser, courlan, bs4, htmldate, dataclasses-json, trafilatura, langchain\n",
            "Successfully installed PyMuPDF-1.22.5 PyTrie-0.4.0 bs4-0.0.1 courlan-0.9.3 dataclasses-json-0.5.14 dateparser-1.1.8 htmldate-1.2.3 justext-3.0.0 langchain-0.0.252 langsmith-0.0.19 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 python-docx-0.8.11 tld-0.13 trafilatura-1.2.2 typing-inspect-0.9.0 unidecode-1.3.6 url-normalize-1.4.3\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.252)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.19)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Collecting paper-qa\n",
            "  Downloading paper_qa-3.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting pypdf (from paper-qa)\n",
            "  Downloading pypdf-3.14.0-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain>=0.0.198 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.0.252)\n",
            "Requirement already satisfied: openai>=0.27.8 in /usr/local/lib/python3.10/dist-packages (from paper-qa) (0.27.8)\n",
            "Collecting faiss-cpu (from paper-qa)\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyCryptodome (from paper-qa)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html2text (from paper-qa)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Collecting tiktoken>=0.4.0 (from paper-qa)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (0.0.19)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.198->paper-qa) (8.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai>=0.27.8->paper-qa) (4.65.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->paper-qa) (2022.10.31)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain>=0.0.198->paper-qa) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.198->paper-qa) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (1.0.0)\n",
            "Installing collected packages: faiss-cpu, pypdf, PyCryptodome, html2text, tiktoken, paper-qa\n",
            "Successfully installed PyCryptodome-3.18.0 faiss-cpu-1.7.4 html2text-2020.1.16 paper-qa-3.5.0 pypdf-3.14.0 tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thirdai import licensing, neural_db as ndb\n",
        "licensing.deactivate()\n",
        "licensing.activate(\"1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3\")"
      ],
      "metadata": {
        "id": "ffKMlZp2GEw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = ndb.NeuralDB(user_id=\"root\")"
      ],
      "metadata": {
        "id": "geI4V7jVGR5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insertable_docs = []\n",
        "csv_files = [f\"{video_id}_transcript.csv\"]\n",
        "\n",
        "for file in csv_files:\n",
        "    csv_doc = ndb.CSV(\n",
        "        path=file,\n",
        "        id_column=\"DOC_ID\",\n",
        "        strong_columns=[\"Transcript\"],\n",
        "        weak_columns=[\"Transcript\"],\n",
        "        reference_columns=[\"Transcript\"])\n",
        "    #\n",
        "    insertable_docs.append(csv_doc)"
      ],
      "metadata": {
        "id": "wcR5Gu7iGUYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_ids = db.insert(insertable_docs, train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbJ2EiFZG4Td",
        "outputId": "58fe457b-e948-4c4c-cf83-fca4fac4614b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded data | source 'Documents:\n",
            "DHjqpvDnNGE_transcript.csv' | vectors 162 | batches 1 | time 0s | complete\n",
            "\n",
            "train | epoch 0 | train_steps 1 | train_hash_precision@5=0.0185185  | train_batches 1 | time 4s\n",
            "\n",
            "train | epoch 1 | train_steps 2 | train_hash_precision@5=0.948148  | train_batches 1 | time 1s\n",
            "\n",
            "train | epoch 2 | train_steps 3 | train_hash_precision@5=0.949383  | train_batches 1 | time 1s\n",
            "\n",
            "train | epoch 3 | train_steps 4 | train_hash_precision@5=0.955556  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 4 | train_steps 5 | train_hash_precision@5=0.940741  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 5 | train_steps 6 | train_hash_precision@5=0.94321  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 6 | train_steps 7 | train_hash_precision@5=0.965432  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 7 | train_steps 8 | train_hash_precision@5=0.975309  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 8 | train_steps 9 | train_hash_precision@5=0.97037  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 9 | train_steps 10 | train_hash_precision@5=0.981481  | train_batches 1 | time 0s\n",
            "\n",
            "train | epoch 10 | train_steps 11 | train_hash_precision@5=0.98642  | train_batches 1 | time 0s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = db.search(\n",
        "    query=\"what is javascript\",\n",
        "    top_k=7,\n",
        "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
        "\n",
        "for result in search_results:\n",
        "    print(result.text)\n",
        "    # print(result.context(radius=1))\n",
        "    # print(result.source)\n",
        "    # print(result.metadata)\n",
        "    print('************')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws-fmvIbG6uo",
        "outputId": "cee1c005-ddaf-463a-9309-25135478fb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "javascript a high level single threaded\n",
            "************\n",
            "button and subscribe if you want to see\n",
            "************\n",
            "file on a website javascript is often\n",
            "************\n",
            "now the event loop will execute this\n",
            "************\n",
            "but javascript also supports classes and\n",
            "************\n",
            "you want to run this file is it a\n",
            "************\n",
            "function whenever a new click occurs\n",
            "************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"openaikey\""
      ],
      "metadata": {
        "id": "4Gtt7pIyHN66"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from paperqa.prompts import qa_prompt\n",
        "from paperqa.chains import make_chain\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name='gpt-3.5-turbo',\n",
        "    temperature=0.6,\n",
        ")\n",
        "\n",
        "qa_chain = make_chain(prompt=qa_prompt, llm=llm)"
      ],
      "metadata": {
        "id": "OyX3Hfz_HUfB"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_references(query):\n",
        "    search_results = db.search(query,top_k=9)\n",
        "    references = []\n",
        "    for result in search_results:\n",
        "        references.append(result.text)\n",
        "    return references\n",
        "\n",
        "def get_answer(query, references):\n",
        "    return qa_chain.run(question=query, context='\\n\\n'.join(references[:9]), answer_length=\"abt 50 words\")"
      ],
      "metadata": {
        "id": "OcnyO1G9HtL4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is javascript?\"\n",
        "\n",
        "references = get_references(query)\n",
        "print(references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWgopNTxHwqd",
        "outputId": "2564a980-b3d4-47fc-b966-da980cbaafb7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['front-end browser or a back-end node.js 78.64 82.72', 'interacts with things like the file 136.959 140.16', 'javascript a high level single threaded 2.08 6.319', 'compiler to convert it to machine code 53.36 57.52', 'engine and chromium use a just-in-time 51.44 55.44', 'react native or ionic and desktop apps 45.28 49.28', 'syntax js code can also run on the 130.959 135.36', 'executing from the global context use 71.28 75.2', 'multi-paradigm dynamic language with a 7.759 11.84']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "references_string = ''.join(references)\n"
      ],
      "metadata": {
        "id": "52XvGJsvRi4j"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "references_string\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "j-lYAwljNoy9",
        "outputId": "1ed54697-9922-4b1e-e9e8-3168e9d501c8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'front-end browser or a back-end node.js 78.64 82.72interacts with things like the file 136.959 140.16javascript a high level single threaded 2.08 6.319compiler to convert it to machine code 53.36 57.52engine and chromium use a just-in-time 51.44 55.44react native or ionic and desktop apps 45.28 49.28syntax js code can also run on the 130.959 135.36executing from the global context use 71.28 75.2multi-paradigm dynamic language with a 7.759 11.84'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = get_answer(query, references_string)\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYehRibEHyv-",
        "outputId": "08c3749b-b25e-421c-8cbf-0ddd7834c5a3"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JavaScript is a programming language primarily used for creating interactive and dynamic web content. It allows developers to add functionality and interactivity to websites by manipulating the Document Object Model (DOM) and responding to user actions. JavaScript can also be used for server-side development with the help of platforms like Node.js. (Mozilla Developer Network, W3Schools)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=\"Transform this into an SEO blog post also make it intuitive inspiring and captivating also make it a little bit on the longer side while maintaining SEO friendliness at the highest level with a title\" + references_string,\n",
        "    temperature=0.9,\n",
        "    max_tokens=500,\n",
        "    top_p=1.0,\n",
        "    frequency_penalty=0.0,\n",
        "    presence_penalty=0.6,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "blog_post = response.choices[0].text.strip()\n"
      ],
      "metadata": {
        "id": "gTzUi4pJH1no"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blog_post"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Ba0xIUt1Xj_7",
        "outputId": "6353c82f-2ccf-4a02-e956-5d7c9b221742"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Unlock the Potential of Node.js and Browser-based JavaScript With a High-Performance Compiler\\n\\nJavaScript is one of the most versatile programming languages in existence, used for everything from scripting to creating powerful web- and mobile-based applications. It's known for its flexibility, ease of use, and high performance, making it a popular choice amongst developers all over the world. But when it comes to optimizing and running code at speeds even approaching the level of traditional compiled languages like C++ or Java, JavaScript sometimes falls short—unless you're using a high-performance compiler.\\n\\nOne such compiler is Node.js, which acts as the engine behind some of today's most powerful cross-platform applications. It transforms code written in JavaScript into a form that can be read and executed more quickly by web browsers and other platforms like React Native and Ionic. Node.js is a single-threaded, multi-paradigm programming language that runs in a global context.\\n\\nThe main advantage of using Node.js for JavaScript code is that it can be executed much faster than when being interpreted by the browser. This makes Node.js an ideal choice for JavaScript-based projects requiring high performance, particularly those involving tasks such as input/output operations, complex algorithms, and heavy calculations. When used with its just-in-time (JIT) compiler, Node.js can execute code up to three times faster than JavaScript alone.\\n\\nNode.js also eliminates the need for additional scripting languages like PHP, allowing your application to remain entirely within the JavaScript realm. This increases performance further, as the code no longer needs to be translated from one language to another. Plus, the popularity of JavaScript means that experienced developers are easy to find and work with.\\n\\nSo, if you're looking to give your JavaScript project a performance boost without sacrificing the flexibility and ease of use that comes with the language, Node.js is the way to go. By combining the power of JavaScript with the speed of a high-performance compiler, you can unlock the potential of your front-end browser, and turn your app into something truly special.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rgr7BpMGYDNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}